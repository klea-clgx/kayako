{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['category_classification_model_admin.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Load the data from admin.jsonl\n",
    "data = []\n",
    "with open(\"admin.jsonl\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        entry = json.loads(line)\n",
    "        data.append(entry)\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extract the entity labels\n",
    "def extract_entity_labels(entities):\n",
    "    return [entity[2] for entity in entities]\n",
    "\n",
    "df['entity_labels'] = df['entities'].apply(extract_entity_labels)\n",
    "\n",
    "# Combine the identified entities with the original text\n",
    "df['combined_text'] = df.apply(lambda row: \" \".join([row['text'][start:end] for start, end, _ in row['entities']]), axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"combined_text\"], df[\"entity_labels\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Entity Classification Model\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Use MultiLabelBinarizer to convert the entity labels to binary arrays\n",
    "binarizer = MultiLabelBinarizer()\n",
    "y_train_binary = binarizer.fit_transform(y_train)\n",
    "y_test_binary = binarizer.transform(y_test)\n",
    "\n",
    "entity_classifier = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "entity_classifier.fit(X_train_vectorized, y_train_binary)\n",
    "# Save the trained model and vectorizer to separate files with different names\n",
    "joblib.dump(vectorizer, \"entity_vectorizer_admin.pkl\")\n",
    "joblib.dump(entity_classifier, \"entity_classification_model_admin.pkl\")\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"combined_text\"], df[\"cats\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Category Classification Model\n",
    "category_vectorizer = TfidfVectorizer()\n",
    "X_train_category_vectorized = category_vectorizer.fit_transform(X_train)\n",
    "X_test_category_vectorized = category_vectorizer.transform(X_test)\n",
    "\n",
    "# Flatten the lists in the \"cats\" column and encode the categorical labels\n",
    "y_train_category_encoded = [item for sublist in y_train for item in sublist]\n",
    "y_test_category_encoded = [item for sublist in y_test for item in sublist]\n",
    "\n",
    "category_encoder = LabelEncoder()\n",
    "y_train_category_encoded = category_encoder.fit_transform(y_train_category_encoded)\n",
    "y_test_category_encoded = category_encoder.transform(y_test_category_encoded)\n",
    "\n",
    "category_model = LogisticRegression(max_iter=1000)\n",
    "category_model.fit(X_train_category_vectorized, y_train_category_encoded)\n",
    "\n",
    "# Save the trained model and vectorizer to separate files with different names\n",
    "joblib.dump(category_vectorizer, \"category_vectorizer_admin.pkl\")\n",
    "joblib.dump(category_model, \"category_classification_model_admin.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Classification Model Report (Train set):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      add_emails       1.00      0.44      0.61        91\n",
      "      add_fields       0.99      0.50      0.67       131\n",
      "       attention       0.00      0.00      0.00         1\n",
      "   change_fields       0.00      0.00      0.00         2\n",
      "          client       0.98      0.91      0.94       374\n",
      "   create_report       0.99      0.55      0.71       172\n",
      "   emails_to_add       1.00      0.42      0.59        78\n",
      "emails_to_remove       0.00      0.00      0.00        23\n",
      "   fields_to_add       0.98      0.48      0.64        96\n",
      "fields_to_change       0.00      0.00      0.00         1\n",
      "fields_to_remove       0.00      0.00      0.00         6\n",
      "  issue_to_check       0.93      0.96      0.95       426\n",
      "   remove_emails       1.00      0.08      0.15        49\n",
      "   remove_fields       0.00      0.00      0.00         9\n",
      "   remove_report       1.00      0.40      0.58        52\n",
      "          urgent       1.00      0.07      0.14        69\n",
      "\n",
      "       micro avg       0.96      0.67      0.79      1580\n",
      "       macro avg       0.62      0.30      0.37      1580\n",
      "    weighted avg       0.95      0.67      0.74      1580\n",
      "     samples avg       0.77      0.63      0.68      1580\n",
      "\n",
      "Entity Classification Model Report (Test set):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      add_emails       0.89      0.35      0.50        23\n",
      "      add_fields       0.93      0.39      0.55        33\n",
      "       attention       0.00      0.00      0.00         0\n",
      "   change_fields       0.00      0.00      0.00         1\n",
      "          client       0.92      0.83      0.87       110\n",
      "   create_report       0.90      0.42      0.58        45\n",
      "   emails_to_add       0.80      0.24      0.36        17\n",
      "emails_to_remove       0.00      0.00      0.00         7\n",
      "   fields_to_add       1.00      0.44      0.61        25\n",
      "fields_to_change       0.00      0.00      0.00         0\n",
      "fields_to_remove       0.00      0.00      0.00         1\n",
      "  issue_to_check       0.82      0.93      0.87        96\n",
      "   remove_emails       1.00      0.16      0.27        19\n",
      "   remove_fields       0.00      0.00      0.00         1\n",
      "   remove_report       1.00      0.25      0.40        12\n",
      "          urgent       1.00      0.04      0.08        25\n",
      "\n",
      "       micro avg       0.88      0.58      0.70       415\n",
      "       macro avg       0.58      0.25      0.32       415\n",
      "    weighted avg       0.88      0.58      0.65       415\n",
      "     samples avg       0.71      0.55      0.60       415\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaydenlea/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kaydenlea/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kaydenlea/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kaydenlea/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kaydenlea/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kaydenlea/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kaydenlea/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = entity_classifier.predict(X_train_vectorized)\n",
    "y_test_pred = entity_classifier.predict(X_test_vectorized)\n",
    "y_train_pred_labels = binarizer.inverse_transform(y_train_pred)\n",
    "y_test_pred_labels = binarizer.inverse_transform(y_test_pred)\n",
    "print(\"Entity Classification Model Report (Train set):\")\n",
    "print(classification_report(y_train_binary, y_train_pred, target_names=binarizer.classes_))\n",
    "print(\"Entity Classification Model Report (Test set):\")\n",
    "print(classification_report(y_test_binary, y_test_pred, target_names=binarizer.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category Classification Model Report (Train Set):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "email_list_edit       0.99      0.89      0.93        87\n",
      "          other       0.96      0.92      0.94       156\n",
      "  report_cancel       1.00      0.75      0.86        52\n",
      "   report_issue       0.88      0.99      0.93       311\n",
      " report_request       0.95      0.91      0.93       194\n",
      "\n",
      "       accuracy                           0.93       800\n",
      "      macro avg       0.96      0.89      0.92       800\n",
      "   weighted avg       0.93      0.93      0.93       800\n",
      "\n",
      "Category Classification Model Report (Test Set):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "email_list_edit       0.95      0.75      0.84        28\n",
      "          other       0.97      0.87      0.92        38\n",
      "  report_cancel       1.00      0.67      0.80        12\n",
      "   report_issue       0.68      0.96      0.80        69\n",
      " report_request       0.87      0.64      0.74        53\n",
      "\n",
      "       accuracy                           0.81       200\n",
      "      macro avg       0.90      0.78      0.82       200\n",
      "   weighted avg       0.84      0.81      0.81       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_category_pred = category_model.predict(X_train_category_vectorized)\n",
    "print(\"Category Classification Model Report (Train Set):\")\n",
    "print(classification_report(y_train_category_encoded, y_train_category_pred, target_names=category_encoder.classes_))\n",
    "\n",
    "# Print classification report for category classification model on the test set\n",
    "y_test_category_pred = category_model.predict(X_test_category_vectorized)\n",
    "print(\"Category Classification Model Report (Test Set):\")\n",
    "print(classification_report(y_test_category_encoded, y_test_category_pred, target_names=category_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Text: I would like to request a new report\n",
      "Entity: create_report\n",
      "Character Range: 24-25 (Character: a)\n",
      "Character Range: 30-36 (Character: report)\n",
      "Entity: issue_to_check\n",
      "Character Range: 13-15 (Character: to)\n",
      "Predicted Email Category: report_request\n"
     ]
    }
   ],
   "source": [
    "# Sample text to test the model\n",
    "sample_text = \"I would like to request a new report\"\n",
    "# Use the entity classification model to predict entities in the sample text\n",
    "sample_text_vectorized = vectorizer.transform([sample_text])\n",
    "predicted_labels = entity_classifier.predict(sample_text_vectorized)\n",
    "predicted_entities = binarizer.inverse_transform(predicted_labels)\n",
    "\n",
    "# Function to get character ranges for each entity\n",
    "def get_character_ranges(text, entity):\n",
    "    ranges = []\n",
    "    start_idx = 0\n",
    "    words = text.split()\n",
    "    for i in range(len(words)):\n",
    "        word = words[i]\n",
    "        end_idx = start_idx + len(word)\n",
    "        if word in entity:\n",
    "            ranges.append((start_idx, end_idx, word))\n",
    "        start_idx = end_idx + 1\n",
    "    return ranges\n",
    "\n",
    "# Use the predicted entities to predict the email category\n",
    "sample_text_category_vectorized = category_vectorizer.transform([sample_text])\n",
    "predicted_category_encoded = category_model.predict(sample_text_category_vectorized)\n",
    "# Use LabelEncoder to convert the numerical category predictions to human-readable text\n",
    "predicted_category_text = category_encoder.inverse_transform(predicted_category_encoded)\n",
    "# Print the results\n",
    "print(\"Sample Text:\", sample_text)\n",
    "# Use the predicted entities to get character ranges in the sample text\n",
    "entities_with_ranges = []\n",
    "for entity in predicted_entities[0]:\n",
    "    ranges = get_character_ranges(sample_text, entity)\n",
    "    entities_with_ranges.append((entity, ranges))\n",
    "\n",
    "for entity, ranges in entities_with_ranges:\n",
    "    print(\"Entity:\", entity)\n",
    "    if ranges:\n",
    "        for start, end, word in ranges:\n",
    "            print(f\"Character Range: {start}-{end} (Character: {word})\")\n",
    "    else:\n",
    "        print(\"Character Range: Not Found\")\n",
    "\n",
    "print(\"Predicted Email Category:\", predicted_category_text[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
